---
title: "DrunkBartender"
author: "Ellis Hughes"
date: "5/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidytuesdayR)
library(tidytext)
library(keras)
library(tokenizers)
library(tidyverse)
library(abind)
library(stringi)
```

## Load Data

```{r load}

tt <- tt_load("2020-05-26")

tt

```

## Prepping for training

For deeplearning, there are several methods for language models. 
The technique I will be using is called "one-hot-encoding". 

what that means is that I will essentially generate matrices for each cocktail name. 
columns represent every single letter, and rows represent which position in the sting
does that letter appear.
Since cocktails can have different length names, I will have to add padding in front of all the cocktails equal to the number of characters I am using to predict the next letter. 

```{r data-parsing}


boston_cocktails <- tt$boston_cocktails %>% 
  distinct(name,ingredient,measure) %>% 
  mutate(
    name = tolower(name),
    ingredient = tolower(ingredient)
  ) %>% 
  group_by(name) %>% 
  summarize(ingredients = paste(ingredient, collapse = ", ")) %>% 
  rename(drink = name) %>% 
  unite("cocktail",drink,ingredients, sep = ": ") %>% 
  pull(cocktail)

hackaton_cocktails <- tt$cocktails %>%
  distinct(drink,ingredient, measure) %>%
  mutate(
    drink = tolower(drink),
    ingredient = tolower(ingredient)
  ) %>%
  group_by(drink) %>%
  summarize(ingredients = paste(ingredient, collapse = ", ")) %>%
  unite("cocktail",drink,ingredients, sep = ": ") %>%
  pull(cocktail)

cocktails <- data.frame(cocktail = c(boston_cocktails,hackaton_cocktails)) %>%
  mutate(
    idx = sample(1:nrow(.),size = nrow(.),replace = FALSE)
  ) %>%
  arrange(idx) %>%
  select(-idx) %>%
  pull(cocktail)

npad_drink <- max(nchar(cocktails))

tokenized_cocktails <- cocktails%>% 
  str_to_lower() %>% 
  tokenize_characters(strip_non_alphanum = FALSE, simplify = FALSE) %>% 
  map(function(x){c(rep("<pad>",npad_drink),x,"ENDOFNAME")})

Outputs <- setdiff(Inputs <- tokenized_cocktails %>%
  {do.call('c',.)}%>%
  unique() %>%
  sort(), "<pad>")

```

```{r one-hot-encoding, eval = FALSE}

skip <- 100

ids <- seq(1, length(tokenized_cocktails), by = skip)

seq_along(ids) %>% 
  
  walk(function(idx_start){
    
    idx <- ids[idx_start]:(ids[idx_start] + skip -1)
    idx <- idx [which(idx < length(tokenized_cocktails))]
      
      
    one_hot <- tokenized_cocktails[idx] %>%
      map(function(cocktail_name){
        x <- array(0, dim = c(length(cocktail_name), npad_drink, length(Inputs)))
        y <- array(0, dim = c(length(cocktail_name), length(Outputs)))
        
        for (i in seq(1, length(cocktail_name) - npad_drink)) {
          textsubset <- cocktail_name[i:(i + npad_drink - 1)]
          x[i, , ] <-
            do.call('cbind', lapply(Inputs, function(x) {
              as.integer(x == textsubset)
            }))
          y[i, ] <-
            as.integer(Outputs == cocktail_name[i + npad_drink])
        }
        
        list(x = x,
             y = y)
      })

    one_hot_x <- one_hot %>%map(`[[`,"x") %>% abind(along = 1)
    one_hot_y <- one_hot %>%map(`[[`,"y") %>% do.call(rbind,.)
    
    saveRDS(list(x = one_hot_x, y = one_hot_y),
            file = paste0("one_hot_data/one_hot_measured", idx_start, ".rds"))
    
  })

```


## Model Set up

```{r model}

batchSize <- 24

full_input_layer <- layer_input(
  shape = c(npad_drink, length(Inputs)),
  name = "full_input")

full_output_layer <- full_input_layer %>%
  layer_cudnn_lstm(units = batchSize)%>%
  layer_dense(units = length(Outputs),activation = "softmax")

cocktail_model <- keras_model(
  inputs = full_input_layer,
  outputs = full_output_layer
  ) 

cocktail_model%>%
  compile(loss = "categorical_crossentropy",
          optimizer = "adam")


```

```{r on-epoch-end}

make_cocktail <- function(model, diversity, guessmax = 300){
  
      sample_mod <- function(preds, temperature = 1){
          preds <- log(preds)/temperature
          exp_preds <- exp(preds)
          preds <- exp_preds/sum(exp(preds))
          
          rmultinom(1, 1, preds) %>% 
            as.integer() %>%
            which.max()
        }
  
  
      splitSeed <- rep("<pad>",npad_drink)
      generated <- ""
      next_char <- ""

      reviewChars<-0

      while(next_char!="ENDOFNAME"){

        x <- data.frame(
          sapply(Inputs, function(x){as.integer(x == splitSeed)})
          ) %>% 
          as.matrix
        
        x <- tensorflow::array_reshape(x, c(1, dim(x)))
        
        preds <-
          try(predict(model, list(x)))
        
        next_index <- sample_mod(preds, diversity)
        next_char <- Outputs[next_index]

        if(next_char != "ENDOFNAME"){
  
          generated <- str_c(generated, next_char, collapse = "")
          splitSeed <- c(splitSeed[-1], next_char)

          reviewChars<-reviewChars+1
        }

        if(reviewChars > guessmax){
          break
        }
      }
      
      return(generated)
}

# prints gobbletygook
cocktail_model %>% 
  make_cocktail(diversity = .8)


```


## Train Model


```{r train}

n_epoch <- 10
n_batch <-list.files(
  path = "one_hot_data",
  pattern = "one_hot_\\d",
  full.names =  TRUE)

for(epoch in 1:n_epoch){
  
  print(paste("EPOCH:",epoch))
  
  batch_train <- sample(n_batch)
  
  for(batch in seq_along(batch_train)){
    
    batch_data <- readRDS(batch_train[batch])
    
    cocktail_model %>% fit(
      batch_data$x,
      batch_data$y,
      batch_size = 128,
      epochs = 1
      )
    
    if(batch %in% c(4, 8, 12)){
      cocktail_model %>% 
        make_cocktail(diversity = .8) %>% 
        print
    }
  }
  
  cocktail_model %>% 
    make_cocktail(diversity = .9) %>% 
    print
  
  save_model_hdf5(cocktail_model,"name_and_contents_multiple_widths_lm.h5")
  
}


```



```{r more-fun}

whats_in_my_cocktail <- function(model, cocktail_name = "Gin Sling", diversity = .8, guessmax = 300){
  
    sample_mod <- function(preds, temperature = 1){
      # preds <- log(preds)/temperature
      # exp_preds <- exp(preds)
      # preds <- exp_preds/sum(exp(preds))
      
      rmultinom(1, 1, preds) %>% 
        as.integer() %>%
        which.max()
    }
      
      tokenized_drink <- tokenize_characters(
        tolower(cocktail_name),
        strip_non_alphanum = FALSE,
        simplify = FALSE)[[1]] %>% 
        c(":")
  
      splitSeed <- c(rep("<pad>",npad_drink-length(tokenized_drink)),
                     tokenized_drink)
      
      generated <- paste0(cocktail_name,":")
      next_char <- ""

      reviewChars<-0

      while(next_char!="ENDOFNAME"){

        x <- data.frame(
          sapply(Inputs, function(x){as.integer(x == splitSeed)})
          ) %>% 
          as.matrix

        # x_short <- tensorflow::array_reshape(x[((-19:0)+npad_drink), ], c(1, 20,ncol(x)))
        x_med <- tensorflow::array_reshape(x[((-39:0)+npad_drink), ], c(1, 40,ncol(x)))
        x <- tensorflow::array_reshape(x, c(1, dim(x)))
        

        preds <-
          try(predict(model, list(
            x
            # ,x_med
            # ,x_short
            )))

        next_index <- sample_mod(preds, diversity)
        next_char <- Outputs[next_index]
        # next_char <- Outputs[which.max(preds)]

        if(next_char != "ENDOFNAME"){
  
          generated <- str_c(generated, next_char, collapse = "")
          splitSeed <- c(splitSeed[-1], next_char)

          reviewChars<-reviewChars+1
        }

        if(reviewChars > guessmax){
          break
        }
      }
      
      return(generated)
}

cocktail_model %>% 
    whats_in_my_cocktail("Other Dave",diversity = .5) %>% 
    print


```


```{r save-as-cpu-version}

old_model <- load_model_hdf5("name_and_contents_multiple_widths_lms.h5")

save_model_weights_hdf5(old_model,"name_and_contents_multiple_widths_lms_weights_trained.h5")

batchSize <- 128

full_input_layer <- layer_input(
  shape = c(npad_drink, length(Inputs)),
  name = "full_input")

full_output_layer <- full_input_layer %>%
  layer_lstm(units = batchSize)%>%
  layer_dense(units = length(Outputs))

med_input_layer <- layer_input(
  shape = c(40, length(Inputs)),
  name = "med_input")

med_output_layer <- med_input_layer %>% 
  layer_lstm(units = batchSize)%>%
  layer_dense(units = length(Outputs))

short_input_layer <- layer_input(
  shape = c(20, length(Inputs)),
  name = "short_input")

short_output_layer <- short_input_layer %>% 
  layer_lstm(units = batchSize)%>%
  layer_dense(units = length(Outputs))

final_output <- layer_concatenate(list(full_output_layer, med_output_layer, short_output_layer)) %>%
  layer_dense(units = length(Outputs)) %>% 
  layer_activation("softmax")

# optimizer <- optimizer_adamax(lr = 0.001)

cocktail_model_cpu <- keras_model(
  inputs = c(full_input_layer,med_input_layer,short_input_layer),
  outputs = final_output
  ) 

cocktail_model_cpu%>%
  compile(loss = "categorical_crossentropy",
          optimizer = "adam")

cocktail_model_cpu %>% 
  load_model_weights_hdf5(
    filepath = "name_and_contents_multiple_widths_lms_weights_trained.h5"
  )

cocktail_model_cpu %>% 
  whats_in_my_cocktail("Gin and tonic")

save_model_hdf5(cocktail_model_cpu,"name_and_contents_multiple_widths_trained_saved_cpu.h5")
old_model <- load_model_hdf5("name_and_contents_multiple_widths_trained_saved_cpu.h5")

```




}
